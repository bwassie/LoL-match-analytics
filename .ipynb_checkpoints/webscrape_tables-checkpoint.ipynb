{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data\n",
    "\n",
    "This notebook will cover the web-scraping and data collection part of the project. I am getting the data from [Tim Sevenhuysen's](https://twitter.com/TimSevenhuysen) website: [Oracle's Elixir](https://oracleselixir.com/). I will scrape and store all player and match statistics from his website into sqlite3 databases. \n",
    "\n",
    "### League of Legends team and player statistics\n",
    "Since most of the data is in HTML tables, I will first use a parser that will make it easier to get these tables. I have copied some code from [Scott Rome](http://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/) who has made an excellent and robust script to extract tables from HTML pages. Basically, we want the statistics for each region in its own databse. This is easy to do since the links are all formatted nicely: for example, all European matches all contain \"/eu/\" in the url. I have a list of such patterns for each region as `to_scrape`. I will create an HTML parser, give it the url and a pattern, and it will get all the tables matching that pattern and put them all in a sqlite3 database. Simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating database na.db and inserting tables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1362: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 213 tables into na.db\n",
      "Creating database eu.db and inserting tables...\n",
      "Inserted 99 tables into eu.db\n",
      "Creating database lck.db and inserting tables...\n",
      "Inserted 71 tables into lck.db\n",
      "Creating database lms.db and inserting tables...\n",
      "Inserted 44 tables into lms.db\n",
      "Creating database lpl.db and inserting tables...\n",
      "Inserted 30 tables into lpl.db\n",
      "Creating database international.db and inserting tables...\n",
      "Inserted 67 tables into international.db\n",
      "Creating database cblol.db and inserting tables...\n",
      "Inserted 30 tables into cblol.db\n",
      "Creating database tcl.db and inserting tables...\n",
      "Inserted 15 tables into tcl.db\n"
     ]
    }
   ],
   "source": [
    "from scrape_utils import HTMLTableParser\n",
    "import os\n",
    "directory = \".\\\\databases\"\n",
    "url = \"https://oracleselixir.com/statistics/player-stats/\"\n",
    "to_scrape = [\"na\",\"eu\",\"lck\",\"lms\",\"lpl\",\"international\",\"cblol\",\"tcl\"]\n",
    "parser = HTMLTableParser()\n",
    "directory = \".\\\\databases\"\n",
    "os.chdir(directory)\n",
    "for ii in to_scrape:\n",
    "    db = ii+\".db\"\n",
    "    parser.scrape_data(url,ii,db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get the data dictionaries for the tables; I'm not sure what some of the columns mean so it's important to have some documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variable                                        Description\n",
      "0       GP                                       Games Played\n",
      "1        W                                               Wins\n",
      "2        L                                             Losses\n",
      "3      AGT  Average Game Time (sometimes also called “G Len”)\n",
      "4       P%  Percentage of games champion was picked in the...\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "url=\"http://oracleselixir.com/definitions/\"\n",
    "conn = sqlite3.connect(\"data_dictionary.db\")\n",
    "hp = HTMLTableParser()\n",
    "table = hp.parse_url(url)[0][1]\n",
    "table.columns = [\"Variable\",\"Description\"]\n",
    "name=\"player_team_stats_dictionary\"\n",
    "print(table.head())\n",
    "table.to_sql(name,con=conn,if_exists='fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match data\n",
    "\n",
    "Now that we have all the team and player statistics, lets put the match data into SQL databases. I had to download the match data and convert it to a CSV in excel beforehand. I will just use Pandas and sqlite3 to create the SQL tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-complete-match-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (6,34,35,36,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017matchdata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-spring-match-data\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, os, glob\n",
    "import pandas as pd\n",
    "directory = \"..\\\\matchdata\"\n",
    "conn = sqlite3.connect(\"match_data.db\")\n",
    "cur = conn.cursor()\n",
    "os.chdir(directory)\n",
    "for ii in glob.glob(\"*.txt\"):\n",
    "    df = pd.read_csv(ii,sep=\"\\t\",encoding='latin')\n",
    "    name=ii.split(\"OraclesElixir\")[0].replace(\"a-\",\"a\")\n",
    "    print(name)\n",
    "    try:\n",
    "        df.to_sql(name,con=conn,if_exists='fail')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some errors about mixed data types but we will take care of those later on! For now, lets get the data dictionary for the match data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variable                                        Description\n",
      "1   gameid         Unique game identifier from Riot’s server.\n",
      "2      url                                 Match history link\n",
      "3   league                                             League\n",
      "4    split  Time period covered, denoted by year and suffi...\n",
      "5     week  Within-split week and day (“week within season...\n"
     ]
    }
   ],
   "source": [
    "directory = \"..\\\\databases\"\n",
    "os.chdir(directory)\n",
    "url=\"http://oracleselixir.com/match-data/match-data-dictionary/\"\n",
    "conn = sqlite3.connect(\"data_dictionary.db\")\n",
    "hp = HTMLTableParser()\n",
    "table = hp.parse_url(url)[0][1]\n",
    "table.columns = [\"Variable\",\"Description\"]\n",
    "table = table.drop(0,axis=0)\n",
    "name=\"matches_data_dictionary\"\n",
    "print(table.head())\n",
    "table.to_sql(name,con=conn,if_exists='fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
